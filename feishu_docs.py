#!/usr/bin/env python3
"""
é£ä¹¦äº‘æ–‡æ¡£æ£€ç´¢æ¨¡å—
æä¾›æ–‡æ¡£æœç´¢ã€å†…å®¹è·å–å’Œæ–‡æœ¬å¤„ç†åŠŸèƒ½
"""

import os
import re
import json
import logging
import requests
from typing import Optional, List, Dict, Any
from dataclasses import dataclass
from dotenv import load_dotenv

from feishu_auth import get_user_access_token, is_user_authorized

load_dotenv()

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# é£ä¹¦ API ç«¯ç‚¹
FEISHU_DOC_SEARCH_URL = "https://open.feishu.cn/open-apis/suite/docs-api/search/object"
FEISHU_DOCX_CONTENT_URL = "https://open.feishu.cn/open-apis/docx/v1/documents/{document_id}/raw_content"
FEISHU_DOC_CONTENT_URL = "https://open.feishu.cn/open-apis/doc/v2/{document_id}/raw_content"
FEISHU_WIKI_SEARCH_URL = "https://open.feishu.cn/open-apis/wiki/v2/spaces/search"

# æ–‡æ¡£ç±»å‹æ˜ å°„
DOC_TYPE_MAP = {
    "doc": "æ—§ç‰ˆæ–‡æ¡£",
    "docx": "æ–°ç‰ˆæ–‡æ¡£",
    "sheet": "ç”µå­è¡¨æ ¼",
    "bitable": "å¤šç»´è¡¨æ ¼",
    "mindnote": "æ€ç»´ç¬”è®°",
    "wiki": "çŸ¥è¯†åº“",
    "file": "æ–‡ä»¶",
    "slide": "å¹»ç¯ç‰‡"
}

# é»˜è®¤é…ç½®
DEFAULT_SEARCH_COUNT = 3
MAX_CONTENT_LENGTH = 4000  # é™åˆ¶è¿”å›ç»™ LLM çš„æœ€å¤§å­—ç¬¦æ•°


@dataclass
class SearchResult:
    """æ–‡æ¡£æœç´¢ç»“æœ"""
    doc_token: str
    doc_type: str
    title: str
    url: str
    owner_name: str = ""
    create_time: str = ""
    update_time: str = ""


@dataclass
class DocumentContent:
    """æ–‡æ¡£å†…å®¹"""
    doc_token: str
    title: str
    content: str
    doc_type: str
    url: str
    truncated: bool = False
    original_length: int = 0


class FeishuDocsManager:
    """é£ä¹¦æ–‡æ¡£ç®¡ç†å™¨"""
    
    def __init__(self, max_content_length: int = MAX_CONTENT_LENGTH):
        """
        åˆå§‹åŒ–æ–‡æ¡£ç®¡ç†å™¨
        
        Args:
            max_content_length: è¿”å›å†…å®¹çš„æœ€å¤§å­—ç¬¦æ•°
        """
        self.max_content_length = max_content_length
    
    def _get_headers(self) -> Dict[str, str]:
        """è·å– API è¯·æ±‚å¤´ï¼ˆåŒ…å« user_access_tokenï¼‰"""
        token = get_user_access_token()
        if not token:
            raise Exception("æœªè·å–åˆ°æœ‰æ•ˆçš„ user_access_tokenï¼Œè¯·å…ˆå®Œæˆ OAuth æˆæƒ")
        
        return {
            "Authorization": f"Bearer {token}",
            "Content-Type": "application/json"
        }
    
    def search_documents(self, query: str, count: int = DEFAULT_SEARCH_COUNT, 
                        doc_types: List[str] = None) -> List[SearchResult]:
        """
        æœç´¢é£ä¹¦æ–‡æ¡£
        
        Args:
            query: æœç´¢å…³é”®è¯
            count: è¿”å›ç»“æœæ•°é‡
            doc_types: æ–‡æ¡£ç±»å‹è¿‡æ»¤ï¼Œå¦‚ ["docx", "doc", "wiki"]
            
        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        if not is_user_authorized():
            logger.warning("âš ï¸ ç”¨æˆ·æœªæˆæƒï¼Œæ— æ³•æœç´¢æ–‡æ¡£")
            return []
        
        logger.info(f"ğŸ” æœç´¢é£ä¹¦æ–‡æ¡£: '{query}'")
        
        # æ„å»ºæœç´¢è¯·æ±‚
        payload = {
            "search_key": query,
            "count": count,
            "offset": 0,
            "owner_ids": [],
            "chat_ids": [],
            "docs_types": doc_types or ["docx", "doc", "wiki"]
        }
        
        try:
            headers = self._get_headers()
            response = requests.post(
                FEISHU_DOC_SEARCH_URL,
                json=payload,
                headers=headers,
                timeout=15
            )
            response.raise_for_status()
            result = response.json()
            
            if result.get("code") != 0:
                error_msg = result.get("msg", "æœªçŸ¥é”™è¯¯")
                logger.error(f"æœç´¢æ–‡æ¡£å¤±è´¥: {error_msg}")
                return []
            
            # è§£ææœç´¢ç»“æœ
            docs_data = result.get("data", {}).get("docs_entities", [])
            search_results = []
            
            for doc in docs_data:
                search_results.append(SearchResult(
                    doc_token=doc.get("docs_token", ""),
                    doc_type=doc.get("docs_type", ""),
                    title=doc.get("title", "æœªçŸ¥æ ‡é¢˜"),
                    url=doc.get("url", ""),
                    owner_name=doc.get("owner", {}).get("name", ""),
                    create_time=doc.get("create_time", ""),
                    update_time=doc.get("update_time", "")
                ))
            
            logger.info(f"âœ… æœç´¢åˆ° {len(search_results)} ä¸ªæ–‡æ¡£")
            return search_results
            
        except requests.exceptions.RequestException as e:
            logger.error(f"æœç´¢æ–‡æ¡£è¯·æ±‚å¤±è´¥: {e}")
            return []
    
    def get_document_content(self, doc_token: str, doc_type: str = "docx") -> Optional[DocumentContent]:
        """
        è·å–æ–‡æ¡£å†…å®¹
        
        Args:
            doc_token: æ–‡æ¡£ Token
            doc_type: æ–‡æ¡£ç±»å‹
            
        Returns:
            æ–‡æ¡£å†…å®¹å¯¹è±¡
        """
        if not is_user_authorized():
            logger.warning("âš ï¸ ç”¨æˆ·æœªæˆæƒï¼Œæ— æ³•è·å–æ–‡æ¡£å†…å®¹")
            return None
        
        logger.info(f"ğŸ“„ è·å–æ–‡æ¡£å†…å®¹: {doc_token} (ç±»å‹: {doc_type})")
        
        # æ ¹æ®æ–‡æ¡£ç±»å‹é€‰æ‹© API
        if doc_type == "docx":
            url = FEISHU_DOCX_CONTENT_URL.format(document_id=doc_token)
        elif doc_type == "doc":
            url = FEISHU_DOC_CONTENT_URL.format(document_id=doc_token)
        else:
            logger.warning(f"âš ï¸ æš‚ä¸æ”¯æŒè·å– {doc_type} ç±»å‹æ–‡æ¡£çš„å†…å®¹")
            return None
        
        try:
            headers = self._get_headers()
            response = requests.get(url, headers=headers, timeout=15)
            response.raise_for_status()
            result = response.json()
            
            if result.get("code") != 0:
                error_msg = result.get("msg", "æœªçŸ¥é”™è¯¯")
                logger.error(f"è·å–æ–‡æ¡£å†…å®¹å¤±è´¥: {error_msg}")
                return None
            
            # æå–å†…å®¹
            content = result.get("data", {}).get("content", "")
            
            # æ¸…æ´—å’Œæˆªæ–­å†…å®¹
            cleaned_content, truncated, original_length = self._clean_and_truncate(content)
            
            return DocumentContent(
                doc_token=doc_token,
                title="",  # æ ‡é¢˜éœ€è¦ä»æœç´¢ç»“æœä¸­è·å–
                content=cleaned_content,
                doc_type=doc_type,
                url="",
                truncated=truncated,
                original_length=original_length
            )
            
        except requests.exceptions.RequestException as e:
            logger.error(f"è·å–æ–‡æ¡£å†…å®¹è¯·æ±‚å¤±è´¥: {e}")
            return None
    
    def _clean_and_truncate(self, content: str) -> tuple:
        """
        æ¸…æ´—å’Œæˆªæ–­æ–‡æ¡£å†…å®¹
        
        Args:
            content: åŸå§‹å†…å®¹
            
        Returns:
            (æ¸…æ´—åçš„å†…å®¹, æ˜¯å¦è¢«æˆªæ–­, åŸå§‹é•¿åº¦)
        """
        if not content:
            return "", False, 0
        
        original_length = len(content)
        
        # æ¸…æ´—å†…å®¹
        # 1. ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
        content = re.sub(r'\n{3,}', '\n\n', content)
        content = re.sub(r' {2,}', ' ', content)
        
        # 2. ç§»é™¤å¯èƒ½çš„ JSON æ ‡è®°æˆ–ç‰¹æ®Šå­—ç¬¦
        content = re.sub(r'\u200b', '', content)  # é›¶å®½ç©ºæ ¼
        
        # 3. æˆªæ–­åˆ°æœ€å¤§é•¿åº¦
        truncated = False
        if len(content) > self.max_content_length:
            # å°è¯•åœ¨å¥å­è¾¹ç•Œæˆªæ–­
            truncate_pos = self.max_content_length
            
            # æŸ¥æ‰¾æœ€è¿‘çš„å¥å·ã€æ¢è¡Œç¬¦
            for delimiter in ['\n\n', 'ã€‚\n', 'ã€‚', '\n', 'ï¼›', 'ï¼', 'ï¼Ÿ']:
                pos = content.rfind(delimiter, 0, self.max_content_length)
                if pos > self.max_content_length * 0.8:
                    truncate_pos = pos + len(delimiter)
                    break
            
            content = content[:truncate_pos]
            content += "\n\n...(å†…å®¹å·²æˆªæ–­)"
            truncated = True
        
        return content.strip(), truncated, original_length
    
    def search_and_retrieve(self, query: str, count: int = DEFAULT_SEARCH_COUNT) -> List[DocumentContent]:
        """
        æœç´¢å¹¶è·å–æ–‡æ¡£å†…å®¹ï¼ˆä¸€ç«™å¼æ–¹æ³•ï¼‰
        
        Args:
            query: æœç´¢å…³é”®è¯
            count: è¿”å›æ–‡æ¡£æ•°é‡
            
        Returns:
            æ–‡æ¡£å†…å®¹åˆ—è¡¨
        """
        # 1. æœç´¢æ–‡æ¡£
        search_results = self.search_documents(query, count)
        
        if not search_results:
            logger.info(f"æœªæœç´¢åˆ°ä¸ '{query}' ç›¸å…³çš„æ–‡æ¡£")
            return []
        
        # 2. è·å–æ¯ä¸ªæ–‡æ¡£çš„å†…å®¹
        documents = []
        for result in search_results:
            content = self.get_document_content(result.doc_token, result.doc_type)
            if content:
                # å¡«å……æœç´¢ç»“æœä¸­çš„ä¿¡æ¯
                content.title = result.title
                content.url = result.url
                documents.append(content)
        
        logger.info(f"âœ… æˆåŠŸè·å– {len(documents)} ä¸ªæ–‡æ¡£å†…å®¹")
        return documents
    
    def format_for_llm(self, documents: List[DocumentContent]) -> str:
        """
        å°†æ–‡æ¡£å†…å®¹æ ¼å¼åŒ–ä¸º LLM å¯ç”¨çš„ä¸Šä¸‹æ–‡
        
        Args:
            documents: æ–‡æ¡£å†…å®¹åˆ—è¡¨
            
        Returns:
            æ ¼å¼åŒ–åçš„æ–‡æœ¬
        """
        if not documents:
            return "æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£ã€‚"
        
        formatted_parts = ["ğŸ“š **æ£€ç´¢åˆ°çš„é£ä¹¦æ–‡æ¡£å†…å®¹ï¼š**\n"]
        
        for i, doc in enumerate(documents, 1):
            truncate_hint = " (å†…å®¹å·²æˆªæ–­)" if doc.truncated else ""
            doc_type_name = DOC_TYPE_MAP.get(doc.doc_type, doc.doc_type)
            
            part = f"""
---
### ğŸ“„ æ–‡æ¡£ {i}: {doc.title}
- ç±»å‹: {doc_type_name}
- é“¾æ¥: {doc.url}
{truncate_hint}

**å†…å®¹:**
{doc.content}
"""
            formatted_parts.append(part)
        
        formatted_parts.append("\n---\nä»¥ä¸Šæ˜¯æ£€ç´¢åˆ°çš„æ–‡æ¡£å†…å®¹ï¼Œè¯·åŸºäºè¿™äº›ä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜ã€‚")
        
        return "\n".join(formatted_parts)


# å…¨å±€å•ä¾‹å®ä¾‹
_docs_manager: Optional[FeishuDocsManager] = None


def get_docs_manager() -> FeishuDocsManager:
    """è·å–å…¨å±€æ–‡æ¡£ç®¡ç†å™¨å®ä¾‹"""
    global _docs_manager
    if _docs_manager is None:
        _docs_manager = FeishuDocsManager()
    return _docs_manager


def search_feishu_knowledge(query: str, count: int = 3) -> str:
    """
    æœç´¢é£ä¹¦çŸ¥è¯†åº“ï¼ˆä¾› LLM Function Calling ä½¿ç”¨ï¼‰
    
    Args:
        query: æœç´¢å…³é”®è¯
        count: è¿”å›æ–‡æ¡£æ•°é‡
        
    Returns:
        æ ¼å¼åŒ–çš„æ–‡æ¡£å†…å®¹å­—ç¬¦ä¸²
    """
    manager = get_docs_manager()
    
    # æ£€æŸ¥æˆæƒçŠ¶æ€
    if not is_user_authorized():
        return "âš ï¸ é£ä¹¦æ–‡æ¡£æ£€ç´¢åŠŸèƒ½æœªæˆæƒã€‚è¯·ç®¡ç†å‘˜å…ˆå®Œæˆ OAuth æˆæƒæµç¨‹ã€‚"
    
    try:
        # æœç´¢å¹¶è·å–æ–‡æ¡£
        documents = manager.search_and_retrieve(query, count)
        
        # æ ¼å¼åŒ–è¿”å›
        return manager.format_for_llm(documents)
        
    except Exception as e:
        logger.error(f"æœç´¢é£ä¹¦æ–‡æ¡£å¤±è´¥: {e}")
        return f"âŒ æœç´¢é£ä¹¦æ–‡æ¡£æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ“š é£ä¹¦æ–‡æ¡£æ£€ç´¢æ¨¡å—æµ‹è¯•")
    print("=" * 60)
    
    # æ£€æŸ¥æˆæƒçŠ¶æ€
    if not is_user_authorized():
        print("\nâš ï¸ ç”¨æˆ·æœªæˆæƒï¼Œè¯·å…ˆè¿è¡Œ feishu_auth.py å®Œæˆ OAuth æˆæƒ")
        print("   python3 feishu_auth.py")
        exit(1)
    
    # æµ‹è¯•æœç´¢
    test_query = input("\nè¯·è¾“å…¥æœç´¢å…³é”®è¯ (é»˜è®¤: æµ‹è¯•): ") or "æµ‹è¯•"
    
    print(f"\næ­£åœ¨æœç´¢: '{test_query}'...")
    result = search_feishu_knowledge(test_query)
    
    print("\n" + "=" * 60)
    print("æœç´¢ç»“æœ:")
    print("=" * 60)
    print(result)
