#!/usr/bin/env python3
"""
é£ä¹¦äº‘æ–‡æ¡£æ£€ç´¢æ¨¡å—ï¼ˆOpenAPI æ–¹å¼ï¼‰
ä½¿ç”¨é£ä¹¦ OpenAPI MCP å®ç°æ–‡æ¡£æœç´¢å’Œå†…å®¹è·å–
"""

import os
import re
import json
import logging
from typing import Optional, List, Dict, Any
from dataclasses import dataclass
from dotenv import load_dotenv

load_dotenv()

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# å°è¯•å¯¼å…¥çœŸå®å®¢æˆ·ç«¯ï¼Œå¦‚æœå¤±è´¥åˆ™å›é€€åˆ°ç®€å•å®¢æˆ·ç«¯
# ä¼˜å…ˆä½¿ç”¨ REST API æ–¹å¼ï¼ˆä¸éœ€è¦ Node.jsï¼Œè§£å†³ Railway å†…å­˜é—®é¢˜ï¼‰
try:
    from rest_api_client import search_feishu_knowledge_real
    HAS_REAL_CLIENT = True
    logger.info("âœ… ä½¿ç”¨ REST API å®¢æˆ·ç«¯ï¼ˆæ—  Node.js å†…å­˜å ç”¨ï¼‰")
except ImportError as e:
    logger.warning(f"âš ï¸  æ— æ³•å¯¼å…¥ REST API å®¢æˆ·ç«¯: {e}")
    # å°è¯•ä½¿ç”¨æ—§çš„ MCP å®¢æˆ·ç«¯
    try:
        from real_openapi_client import search_feishu_knowledge_real
        HAS_REAL_CLIENT = True
        logger.info("âœ… ä½¿ç”¨ OpenAPI MCP å®¢æˆ·ç«¯")
    except ImportError:
        HAS_REAL_CLIENT = False
        logger.warning("âš ï¸  æ— æ³•å¯¼å…¥ OpenAPI å®¢æˆ·ç«¯ï¼Œä½¿ç”¨ç®€å•å®¢æˆ·ç«¯")
        from simple_openapi_client import search_feishu_knowledge_simple

# é»˜è®¤é…ç½®
DEFAULT_SEARCH_COUNT = 3
MAX_CONTENT_LENGTH = 4000

@dataclass
class SearchResult:
    """æ–‡æ¡£æœç´¢ç»“æœ"""
    doc_token: str
    doc_type: str
    title: str
    url: str
    owner_name: str = ""
    create_time: str = ""
    update_time: str = ""

@dataclass
class DocumentContent:
    """æ–‡æ¡£å†…å®¹"""
    doc_token: str
    title: str
    content: str
    doc_type: str
    url: str
    truncated: bool = False
    original_length: int = 0

class FeishuOpenAPIDocsManager:
    """é£ä¹¦ OpenAPI æ–‡æ¡£ç®¡ç†å™¨"""
    
    def __init__(self, max_content_length: int = MAX_CONTENT_LENGTH):
        self.max_content_length = max_content_length
    
    def search_documents(self, query: str, count: int = DEFAULT_SEARCH_COUNT) -> List[SearchResult]:
        """
        æœç´¢é£ä¹¦æ–‡æ¡£ï¼ˆä½¿ç”¨ OpenAPI æ–¹å¼ï¼‰
        """
        logger.info(f"ğŸ” ä½¿ç”¨ OpenAPI æœç´¢é£ä¹¦æ–‡æ¡£: '{query}'")
        
        try:
            # ä½¿ç”¨ç®€åŒ–ç‰ˆå®¢æˆ·ç«¯è¿›è¡Œæœç´¢
            result_text = search_feishu_knowledge_simple(query, count)
            
            # è§£æç»“æœæ–‡æœ¬ï¼Œæå–æ–‡æ¡£ä¿¡æ¯
            search_results = []
            
            # ç®€å•è§£æ - ä»æ ¼å¼åŒ–æ–‡æœ¬ä¸­æå–æ–‡æ¡£ä¿¡æ¯
            if "æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£" not in result_text:
                # è¿™é‡Œå¯ä»¥æ ¹æ®å®é™…è¿”å›æ ¼å¼è¿›è¡Œè§£æ
                # æš‚æ—¶è¿”å›æ¨¡æ‹Ÿç»“æœ
                search_results.append(SearchResult(
                    doc_token="test_doc_token",
                    doc_type="docx",
                    title=f"æœç´¢ç»“æœ: {query}",
                    url="https://k7ftx11633c.feishu.cn/docx/test_doc_token"
                ))
            
            logger.info(f"âœ… OpenAPI æœç´¢åˆ° {len(search_results)} ä¸ªæ–‡æ¡£")
            return search_results
            
        except Exception as e:
            logger.error(f"âŒ OpenAPI æ–‡æ¡£æœç´¢å¤±è´¥: {e}")
            return []
    
    def get_document_content(self, doc_token: str, doc_type: str = "docx") -> Optional[DocumentContent]:
        """
        è·å–æ–‡æ¡£å†…å®¹ï¼ˆä½¿ç”¨ OpenAPI æ–¹å¼ï¼‰
        """
        logger.info(f"ğŸ“„ ä½¿ç”¨ OpenAPI è·å–æ–‡æ¡£å†…å®¹: {doc_token}")
        
        try:
            # ä½¿ç”¨ç®€åŒ–ç‰ˆå®¢æˆ·ç«¯è·å–å†…å®¹
            result_text = search_feishu_knowledge_simple(doc_token, 1)
            
            if "æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£" in result_text:
                return None
            
            # æ¸…æ´—å’Œæˆªæ–­å†…å®¹
            cleaned_content, truncated, original_length = self._clean_and_truncate(result_text)
            
            return DocumentContent(
                doc_token=doc_token,
                title=f"æ–‡æ¡£: {doc_token}",
                content=cleaned_content,
                doc_type=doc_type,
                url=f"https://k7ftx11633c.feishu.cn/docx/{doc_token}",
                truncated=truncated,
                original_length=original_length
            )
            
        except Exception as e:
            logger.error(f"âŒ OpenAPI è·å–æ–‡æ¡£å¤±è´¥: {e}")
            return None
    
    def _clean_and_truncate(self, content: str) -> tuple:
        """æ¸…æ´—å’Œæˆªæ–­æ–‡æ¡£å†…å®¹"""
        if not content:
            return "", False, 0
        
        original_length = len(content)
        
        # æ¸…æ´—å†…å®¹
        # 1. ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
        content = re.sub(r'\n{3,}', '\n\n', content)
        content = re.sub(r' {2,}', ' ', content)
        
        # 2. ç§»é™¤å¯èƒ½çš„ JSON æ ‡è®°æˆ–ç‰¹æ®Šå­—ç¬¦
        content = re.sub(r'\u200b', '', content)  # é›¶å®½ç©ºæ ¼
        
        # 3. æˆªæ–­åˆ°æœ€å¤§é•¿åº¦
        truncated = False
        if len(content) > self.max_content_length:
            # å°è¯•åœ¨å¥å­è¾¹ç•Œæˆªæ–­
            truncate_pos = self.max_content_length
            
            # æŸ¥æ‰¾æœ€è¿‘çš„å¥å·ã€æ¢è¡Œç¬¦
            for delimiter in ['\n\n', 'ã€‚\n', 'ã€‚', '\n', 'ï¼›', 'ï¼', 'ï¼Ÿ']:
                pos = content.rfind(delimiter, 0, self.max_content_length)
                if pos > self.max_content_length * 0.8:
                    truncate_pos = pos + len(delimiter)
                    break
            
            content = content[:truncate_pos]
            content += "\n\n...(å†…å®¹å·²æˆªæ–­)"
            truncated = True
        
        return content.strip(), truncated, original_length
    
    def search_and_retrieve(self, query: str, count: int = DEFAULT_SEARCH_COUNT) -> List[DocumentContent]:
        """æœç´¢å¹¶è·å–æ–‡æ¡£å†…å®¹ï¼ˆä¸€ç«™å¼æ–¹æ³•ï¼‰"""
        # 1. æœç´¢æ–‡æ¡£
        search_results = self.search_documents(query, count)
        
        if not search_results:
            logger.info(f"æœªæœç´¢åˆ°ä¸ '{query}' ç›¸å…³çš„æ–‡æ¡£")
            return []
        
        # 2. è·å–æ¯ä¸ªæ–‡æ¡£çš„å†…å®¹
        documents = []
        for result in search_results:
            content = self.get_document_content(result.doc_token, result.doc_type)
            if content:
                # å¡«å……æœç´¢ç»“æœä¸­çš„ä¿¡æ¯
                content.title = result.title
                content.url = result.url
                documents.append(content)
        
        logger.info(f"âœ… æˆåŠŸè·å– {len(documents)} ä¸ªæ–‡æ¡£å†…å®¹")
        return documents
    
    def format_for_llm(self, documents: List[DocumentContent]) -> str:
        """å°†æ–‡æ¡£å†…å®¹æ ¼å¼åŒ–ä¸º LLM å¯ç”¨çš„ä¸Šä¸‹æ–‡"""
        if not documents:
            return "æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£ã€‚"
        
        formatted_parts = ["ğŸ“š **æ£€ç´¢åˆ°çš„é£ä¹¦æ–‡æ¡£å†…å®¹ï¼š**\n"]
        
        for i, doc in enumerate(documents, 1):
            truncate_hint = " (å†…å®¹å·²æˆªæ–­)" if doc.truncated else ""
            doc_type_name = "æ–‡æ¡£"  # ç®€åŒ–å¤„ç†
            
            part = f"""
---
### ğŸ“„ æ–‡æ¡£ {i}: {doc.title}
- ç±»å‹: {doc_type_name}
- é“¾æ¥: {doc.url}
{truncate_hint}

**å†…å®¹:**
{doc.content}
"""
            formatted_parts.append(part)
        
        formatted_parts.append("\n---\nä»¥ä¸Šæ˜¯æ£€ç´¢åˆ°çš„æ–‡æ¡£å†…å®¹ï¼Œè¯·åŸºäºè¿™äº›ä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜ã€‚")
        
        return "\n".join(formatted_parts)

# å…¨å±€å•ä¾‹å®ä¾‹
_docs_manager: Optional[FeishuOpenAPIDocsManager] = None

def get_docs_manager() -> FeishuOpenAPIDocsManager:
    """è·å–å…¨å±€æ–‡æ¡£ç®¡ç†å™¨å®ä¾‹"""
    global _docs_manager
    if _docs_manager is None:
        _docs_manager = FeishuOpenAPIDocsManager()
    return _docs_manager

def search_feishu_knowledge(query: str, count: int = 3) -> str:
    """
    æœç´¢é£ä¹¦çŸ¥è¯†åº“ï¼ˆä¾› LLM Function Calling ä½¿ç”¨ï¼‰
    
    Args:
        query: æœç´¢å…³é”®è¯
        count: è¿”å›æ–‡æ¡£æ•°é‡
        
    Returns:
        æ ¼å¼åŒ–çš„æ–‡æ¡£å†…å®¹å­—ç¬¦ä¸²
    """
    # ä¼˜å…ˆä½¿ç”¨çœŸå®å®¢æˆ·ç«¯
    if HAS_REAL_CLIENT:
        try:
            logger.info(f"ğŸ” ä½¿ç”¨çœŸå® OpenAPI å®¢æˆ·ç«¯æœç´¢: '{query}'")
            return search_feishu_knowledge_real(query, count)
        except Exception as e:
            logger.error(f"çœŸå®å®¢æˆ·ç«¯æœç´¢å¤±è´¥: {e}")
            # å›é€€åˆ°ç®€å•å®¢æˆ·ç«¯
            pass
    
    # ä½¿ç”¨ç®€å•å®¢æˆ·ç«¯æˆ–å›é€€
    try:
        logger.info(f"ğŸ” ä½¿ç”¨ç®€å• OpenAPI å®¢æˆ·ç«¯æœç´¢: '{query}'")
        return search_feishu_knowledge_simple(query, count)
    except Exception as e:
        logger.error(f"æœç´¢é£ä¹¦æ–‡æ¡£å¤±è´¥: {e}")
        return f"âŒ æœç´¢é£ä¹¦æ–‡æ¡£æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"

# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ“š é£ä¹¦æ–‡æ¡£æ£€ç´¢æ¨¡å—æµ‹è¯• (OpenAPI æ–¹å¼)")
    print("=" * 60)
    
    # æµ‹è¯•æœç´¢
    test_query = input("\nè¯·è¾“å…¥æœç´¢å…³é”®è¯ (é»˜è®¤: æµ‹è¯•): ") or "æµ‹è¯•"
    
    print(f"\næ­£åœ¨æœç´¢: '{test_query}'...")
    result = search_feishu_knowledge(test_query)
    
    print("\n" + "=" * 60)
    print("æœç´¢ç»“æœ:")
    print("=" * 60)
    print(result)